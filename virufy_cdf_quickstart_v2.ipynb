{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyK-jXRq6STy"
      },
      "source": [
        "# Virufy COVID Quickstart\n",
        "\n",
        "Hello fellow fighters! We welcome you as allies in the battle against COVID-19. This notebook provides a quick tutorial on how to download our data, preprocess it, and quickly get started training models. \n",
        "\n",
        "## Part 1: Setup\n",
        "\n",
        "First, we import some packages. If you are running this in Colab they should all come pre-installed. If you're running this locally, you might need to install these packages first. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CCRzH5S6STz",
        "outputId": "78c2ebfe-96c6-4b00-f3e9-68913d5125cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uqO7GDQ6ST0"
      },
      "source": [
        "## Part 2: Data Download\n",
        "\n",
        "Now, we download the CoughVID data from a different, open-source Virufy repo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD0h8awkxYmp"
      },
      "outputs": [],
      "source": [
        "# Download coughvid data in CDF format\n",
        "# Run once \n",
        "!git clone \"https://github.com/virufy/virufy-cdf-coughvid.git\"\n",
        "%cd virufy-cdf-coughvid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2D40YVo6ST1"
      },
      "source": [
        "## Part 3: Data Cleaning\n",
        "Now we're ready to load our data into memory! \n",
        "\n",
        "If you listen to the recordings, you might notice that some of the recordings aren't coughs. To help you, we've already run a model to predict whether the sound file is really a cough. Here, we filter our dataset, keeping only those recordings that are at least 70% likely to be coughs.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kissg73b6ST1"
      },
      "outputs": [],
      "source": [
        "coughvid = pd.read_csv(\"virufy-cdf-coughvid.csv\")\n",
        "msk = (coughvid.loc[:,'cough_detected'] >= 0.99)\n",
        "coughvid = coughvid.loc[msk,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isY_07hq6ST1"
      },
      "source": [
        "Let's take a quick look at our labels! \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDSOlGx_vrVN"
      },
      "outputs": [],
      "source": [
        "# Filtering cough_detected to > .7 is advisable\n",
        "# The .7 threshold can be tuned as part of model development, we recommend testing different thresholds after a model has been completed\n",
        "coughvid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZqZ2t6OMf5y"
      },
      "outputs": [],
      "source": [
        "# Disclaimer: we have inferred some of these pcr_test_result labels based on other columns\n",
        "# Target = pcr_test_result_inferred\n",
        "# Positive, negative, untested\n",
        "\n",
        "coughvid['pcr_test_result_inferred'].head(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEokMYCb6ST2"
      },
      "source": [
        "There are a lot of recordings labeled as 'untested'. These can't be directly used in supervised learning, so for now we'll filter out those labels as well, keeping only the recordings that are 'positive' or 'negative'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Nuq3N9J4GJ0"
      },
      "outputs": [],
      "source": [
        "# Filter out untested results\n",
        "msk = (coughvid.loc[:,'pcr_test_result_inferred']=='untested')\n",
        "coughvid = coughvid.loc[~msk,:]\n",
        "coughvid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT99s8As6ST2"
      },
      "source": [
        "Our cleaned data consists of 5386 recordings, each labelled with 'positive' or 'negative' and a selection of clinical features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svMr48bB6ST2"
      },
      "source": [
        "## Part 4: Data Preprocessing\n",
        "\n",
        "Now that we have a clean dataset, we split it into train/val. We'll train on the train split and use the val split to decide when to stop training. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjer8iA7_EvO"
      },
      "outputs": [],
      "source": [
        "# Test/Train split\n",
        "stratify_labels = coughvid[\"pcr_test_result_inferred\"].map(lambda x: x if x is \"positive\" else \"untested\")\n",
        "cdf_train, cdf_test = train_test_split(coughvid, test_size=0.2, random_state = 0, stratify = stratify_labels, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeHA8st5eIQ7",
        "outputId": "427d06b0-b6f6-4cdf-b7f3-693a692de580"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2218, 16), (555, 16))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "cdf_train.shape, cdf_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYeTmXvN5xa4",
        "outputId": "69b2d9d2-6dde-46dd-a137-1e0e9a8cd8f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(451, 1767)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "sum(cdf_train['pcr_test_result_inferred'] == 'positive'), sum(cdf_train['pcr_test_result_inferred'] == 'negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcUgqRXx8fhi"
      },
      "outputs": [],
      "source": [
        "sum(cdf_test['pcr_test_result_inferred'] == 'positive'), sum(cdf_test['pcr_test_result_inferred'] == 'negative')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gENDp7266ST3"
      },
      "source": [
        "Here, we define our custom preprocessing pipeline. We extract the following relevant audio features:\n",
        "- Mel-Frequency Cepstral Coefficients (MFCCs) \n",
        "- Mel-Spectrograms\n",
        "\n",
        "We also cache these features so that the preprocessing only needs to be run once. \n",
        "Feel free to modify this section in any way you like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbkU4Tb6lzR8"
      },
      "outputs": [],
      "source": [
        "# Functions to process audio files into images and json features\n",
        "def trim_silence(x, *args):\n",
        "    try:pad,db_max,frame_length,hop_length = args[0],args[1],args[2],args[3]\n",
        "    except: \n",
        "        print('Please enter the following arguments: pad,db_max,frame_length,hop_length')\n",
        "        return\n",
        "\n",
        "    _, ints = librosa.effects.trim(x, top_db=db_max, frame_length=256, hop_length=64)\n",
        "    start = int(max(ints[0]-pad, 0))\n",
        "    end   = int(min(ints[1]+pad, len(x)))\n",
        "    return x[start:end]\n",
        "\n",
        "def process_cough_file(path,trim,*args):\n",
        "    try: sr,removeaudio,chunk,db_max = args[0],args[1],args[2],args[3]\n",
        "    except: \n",
        "        sr,removeaudio,chunk,db_max= 22050,False,3,50\n",
        "    try:\n",
        "        x,sr = librosa.load(path, sr=sr)       \n",
        "    except: \n",
        "        return -1\n",
        "    \n",
        "    if len(x)/sr < 0.3 or len(x)/sr > 30:\n",
        "        return None,None  \n",
        "    hop_length = np.floor(0.010*sr).astype(int) #10ms\n",
        "    win_length = np.floor(0.020*sr).astype(int) #20ms  \n",
        "\n",
        "    if removeaudio:\n",
        "        os.remove(path)\n",
        "    \n",
        "    x = trim(x, 0.25*sr, db_max,win_length,hop_length) \n",
        "    x = x[:np.floor(chunk*sr).astype(int)]\n",
        "    \n",
        "    #pads to chunk size if smaller\n",
        "    x_pad = np.zeros(int(sr*chunk))\n",
        "    x_pad[:min(len(x_pad), len(x))] = x[:min(len(x_pad), len(x))]\n",
        "\n",
        "    return [x_pad,sr,hop_length,win_length]\n",
        "\n",
        "def get_melspec(sdir,audio,sr,name):\n",
        "    # Mel Spectogram\n",
        "    audio = librosa.util.fix_length(audio, size=154350)\n",
        "    melspec  = librosa.feature.melspectrogram(y=audio,sr=sr,n_mels=128, fmax=8000)\n",
        "    s_db     = librosa.power_to_db(melspec, ref=np.max)\n",
        "    rawSBD = s_db.T.tolist()\n",
        "    return rawSBD\n",
        "\n",
        "def get_rawMFCCs(audio,sr,*args):\n",
        "    try: hop_length,win_length,n_mfcc,n_mels,n_ftt = args[0],args[1],args[2],args[3],args[4]\n",
        "    except:\n",
        "        hop_length = np.floor(0.010*sr).astype(int) #10ms\n",
        "        win_length = np.floor(0.020*sr).astype(int) #20ms  \n",
        "        n_mfcc,n_mels,n_ftt=13,13,2048\n",
        "    \n",
        "    audio = librosa.util.fix_length(audio, size=154350)\n",
        "    rawMFCCs = librosa.feature.mfcc(y=audio,sr=sr, n_mfcc=n_mfcc,n_mels=n_mels, n_fft=n_ftt, hop_length=hop_length)\n",
        "    # rawMFCCs    = np.mean(rawMFCCs.T,axis=0).tolist()\n",
        "    rawMFCCs = rawMFCCs.T.tolist()\n",
        "\n",
        "    return rawMFCCs\n",
        "\n",
        "def getlabel(key, dataframe, chosen):\n",
        "      return dataframe.loc[dataframe[chosen['id']]==key][chosen['pcr']].tolist()[0]\n",
        "\n",
        "def extract(df, chosen, savedir):\n",
        "    if not os.path.isdir(savedir):\n",
        "        os.mkdir(savedir)\n",
        "        \n",
        "    keys, dirs = df[chosen['id']].tolist(),df[chosen['path']].tolist()  \n",
        "    audio_objs = [process_cough_file(path,trim_silence) for path in dirs]\n",
        "    false_indices = [i for i in range(len(audio_objs)) if isinstance(audio_objs[i],int) or isinstance(audio_objs[i],tuple)]\n",
        "\n",
        "    audio_objs = [audio_objs[i] for i in range(len(audio_objs)) if i not in false_indices]\n",
        "    audio_objs = np.array(audio_objs)\n",
        "    audio,sr,hop_length,win_length = audio_objs[:,0],audio_objs[:,1],audio_objs[:,2],audio_objs[:,3]\n",
        "    \n",
        "    dirs = [dirs[i] for i in range(len(dirs)) if i not in false_indices]\n",
        "    keys = [keys[i] for i in range(len(keys)) if i not in false_indices]\n",
        "    data = {\n",
        "              key:{\n",
        "                    'DIR':get_melspec(savedir,a_i,sr_i,key),\n",
        "                    'rawMFCC':get_rawMFCCs(a_i,sr_i),\n",
        "                    'label':getlabel(key, df, chosen)\n",
        "                  } for key,a_i,sr_i in list(zip(keys,audio,sr))\n",
        "            }\n",
        "    return data\n",
        "\n",
        "    \n",
        "def filter_DF(df):\n",
        "    names = list(df.columns)\n",
        "    chosen= {}\n",
        "    for name in names:\n",
        "        if 'inferred' in name.lower():chosen['pcr'] = name # Choosing the target (pcr_test_result_inferred)\n",
        "        elif 'path' in name.lower():chosen['path'] = name\n",
        "        elif 'patient' in name.lower() or 'id' == name.lower() :chosen['id'] = name\n",
        "    return df[[chosen['id'],chosen['pcr'],chosen['path']]].dropna().reset_index(), chosen \n",
        "\n",
        "def extract_features(train_df, test_df, dir_train, dir_test):\n",
        "    train_dataframe, train_chosen = filter_DF(train_df)\n",
        "    test_dataframe, test_chosen = filter_DF(test_df)\n",
        "    \n",
        "    train_features = extract(train_dataframe, train_chosen, dir_train)\n",
        "    test_features = extract(test_dataframe, test_chosen, dir_test)\n",
        "    \n",
        "    return train_features, test_features\n",
        "\n",
        "\n",
        "def show_image(_image):\n",
        "    fig, ax = plt.subplots()\n",
        "    img = librosa.display.specshow(_image, ax=ax)\n",
        "    plt.style.use('classic')\n",
        "    plt.xlabel('time')\n",
        "    plt.ylabel('frequency')\n",
        "    fig.colorbar(img, ax=ax)\n",
        "    ax.set(title='IMG')\n",
        "    plt.show()\n",
        "    pass\n",
        "\n",
        "\n",
        "import pickle\n",
        "def save_dump(file_path, data, labels):\n",
        "    file = open(file_path, 'wb')\n",
        "    # dump information to that file\n",
        "    pickle.dump((data, labels), file)\n",
        "    # close the file\n",
        "    file.close()\n",
        "    pass\n",
        "\n",
        "\n",
        "def load_data(path_file):\n",
        "    file = open(path_file, 'rb')\n",
        "\n",
        "    # dump information to that file\n",
        "    (pixels, labels) = pickle.load(file)\n",
        "\n",
        "    # close the file\n",
        "    file.close()\n",
        "\n",
        "    print(pixels.shape)\n",
        "    print(labels.shape)\n",
        "    return pixels, labels\n",
        "\n",
        "\n",
        "def view_chart(performance, people, chart):\n",
        "    fig, ax = plt.subplots()\n",
        "    y_pos = np.arange(len(people))\n",
        "    ax.barh(y_pos, performance, align='center', color=['dodgerblue','orange'])\n",
        "    for index, value in enumerate(performance):\n",
        "        plt.text(value, index, str(value))\n",
        "    ax.set_yticks(y_pos)\n",
        "    ax.set_yticklabels(people)\n",
        "    ax.invert_yaxis()\n",
        "    ax.set_xlabel('Number')\n",
        "    ax.set_title(chart)\n",
        "    plt.xlim(0, max(performance) + 400)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G5CYUej89Bi"
      },
      "outputs": [],
      "source": [
        "!pip install audiomentations\n",
        "import IPython.display as ipd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from audiomentations import Compose, TimeStretch, PitchShift, Shift, Trim, Gain, PolarityInversion, AddGaussianNoise, BandPassFilter, BandStopFilter\n",
        "from audiomentations import GainTransition\n",
        "from audiomentations import SpecCompose, SpecChannelShuffle, SpecFrequencyMask, FrequencyMask\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def save_csv_data(data_dict, dir):\n",
        "    uuid = np.array([feat for feat in data_dict])\n",
        "    image = np.array([data_dict[feat]['DIR'] for feat in data_dict])\n",
        "    label = np.array([data_dict[feat]['label'] for feat in data_dict])\n",
        "    metadata_image_mfc = {\n",
        "        'uuid': uuid,\n",
        "        'images': image,\n",
        "        'assessment_result': label,\n",
        "    }\n",
        "    df = pd.DataFrame(metadata_image_mfc, columns=['uuid', 'images', 'assessment_result'])\n",
        "    df.to_csv(dir, index=False, header=True)\n",
        "    pass\n",
        "\n",
        "# save_csv_data(train_features, '/content/drive/MyDrive/Data-Covid/virufy-data-train.csv')\n",
        "# save_csv_data(test_features, '/content/drive/MyDrive/Data-Covid/virufy-data-test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lENtkyDB9G_v"
      },
      "outputs": [],
      "source": [
        "augment_1 = Compose([\n",
        "    TimeStretch(min_rate=0.7, max_rate=1.4, p=0.9),\n",
        "    PitchShift(min_semitones=-2, max_semitones=4, p=1),\n",
        "    Shift(min_fraction=-0.5, max_fraction=0.5, p=0.8),\n",
        "    Trim(p=1),\n",
        "    GainTransition(p=1),\n",
        "    PolarityInversion(p=0.5),\n",
        "])\n",
        "\n",
        "# augment_2 = Compose([\n",
        "#     TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
        "#     PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "#     Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
        "#     GainTransition(p=1),\n",
        "#     Trim(p=0.5),\n",
        "#     PolarityInversion(p=0.7),\n",
        "# ])\n",
        "\n",
        "# augment_3 = Compose([\n",
        "#     TimeStretch(min_rate=0.7, max_rate=1.4, p=0.9),\n",
        "#     PitchShift(min_semitones=-2, max_semitones=4, p=1),\n",
        "#     Shift(min_fraction=-0.5, max_fraction=0.5, p=0.8),\n",
        "#     Trim(p=0.5),\n",
        "#     FrequencyMask(p=0.5),\n",
        "# ])\n",
        "\n",
        "# augment_3 = SpecCompose(\n",
        "#     [\n",
        "#         SpecChannelShuffle(p=0.5),\n",
        "#         SpecFrequencyMask(p=0.5),\n",
        "#         Trim(p=1),\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "augment_global = Compose([\n",
        "    Trim(p=1),             \n",
        "])\n",
        "\n",
        "\n",
        "def data_augmentation(df, chosen, savedir, status):\n",
        "    if not os.path.isdir(savedir):\n",
        "        os.mkdir(savedir)\n",
        "        \n",
        "    keys, dirs, labels = df[chosen['id']].tolist(), df[chosen['path']].tolist(), df[chosen['pcr']].tolist()\n",
        "\n",
        "    print(\"P :\", sum(df[chosen['pcr']] == 'positive'))\n",
        "    print(\"N :\", sum(df[chosen['pcr']] == 'negative'))\n",
        "\n",
        "\n",
        "    # print(dirs)\n",
        "\n",
        "    # audio_objs = [process_cough_file(path,trim_silence) for path in dirs]\n",
        "    # false_indices = [i for i in range(len(audio_objs)) if isinstance(audio_objs[i],int) or isinstance(audio_objs[i],tuple)]\n",
        "\n",
        "    # audio_objs = [audio_objs[i] for i in range(len(audio_objs)) if i not in false_indices]\n",
        "    # audio_objs = np.array(audio_objs)\n",
        "\n",
        "    # # print(audio_objs)\n",
        "\n",
        "    # audio,sr,hop_length,win_length = audio_objs[:,0],audio_objs[:,1],audio_objs[:,2],audio_objs[:,3]\n",
        "    \n",
        "    # dirs = [dirs[i] for i in range(len(dirs)) if i not in false_indices]\n",
        "    # keys = [keys[i] for i in range(len(keys)) if i not in false_indices]\n",
        "\n",
        "    # data_path = []\n",
        "    data_librosa = []\n",
        "    data_uuid = []\n",
        "    data_labels = []\n",
        "    for key, path, label in list(zip(keys, dirs, labels)):\n",
        "         \n",
        "        # print(key)\n",
        "        a_i, sr_i = librosa.load(path, 22050)\n",
        "        # write(savedir + key + '.wav', sr_i, a_i)\n",
        "\n",
        "        sr_i = 22050\n",
        "        data_global = augment_global(a_i, sr_i)\n",
        "        # img = get_melspec(savedir, data_global, sr_i, key)\n",
        "        img = get_rawMFCCs(data_global, sr_i)\n",
        "        # print(np.array(img).shape)\n",
        "        # data_path.append(key + '.png')\n",
        "        data_librosa.append(img)\n",
        "        data_uuid.append(key)\n",
        "        data_labels.append(label)\n",
        "\n",
        "        if label == 'positive' and status == True:\n",
        "            data_aug_1 = augment_1(a_i, sr_i)\n",
        "            # img_aug_1 = get_melspec(savedir, data_aug_1, sr_i, key + '_aug_1')\n",
        "            img_aug_1 = get_rawMFCCs(data_aug_1, sr_i)\n",
        "            # data_path.append(key + '_aug_1.png')\n",
        "            # print(np.array(img_aug_1).shape)\n",
        "            data_librosa.append(img_aug_1)\n",
        "            data_uuid.append(key + '_aug_1')\n",
        "            data_labels.append(label)\n",
        "            # print(key + '_aug_1')\n",
        "\n",
        "            # data_aug_2 = augment_2(a_i, sr_i)\n",
        "            # img_aug_2 = get_melspec(savedir, data_aug_2, sr_i, key + '_aug_2')\n",
        "            # data_path.append(key + '_aug_2.png')\n",
        "            # data_uuid.append(key + '_aug_2')\n",
        "            # data_labels.append(label)\n",
        "            # print(img_aug_2)\n",
        "\n",
        "            # data_aug_3 = augment_3(a_i, sr_i)\n",
        "            # img_aug_3 = get_melspec(savedir, data_aug_3, sr_i, key + '_aug_3')\n",
        "            # data_path.append(key + '_aug_3.png')\n",
        "            # data_uuid.append(key + '_aug_3')\n",
        "            # data_labels.append(label)\n",
        "            # print(img_aug_3)\n",
        "\n",
        "            # write(savedir + key + '_not_noise.wav', sr_i, data_not_noise)\n",
        "            # write(savedir + key + '_add_noise.wav', sr_i, data_noise)\n",
        "    return np.array(data_uuid), np.array(data_librosa), np.array(data_labels)\n",
        "\n",
        "\n",
        "def save_csv_data_audio(data_uuid, data_path, data_labels, savedir, name):\n",
        "    # df, chosen = filter_DF(train_df)\n",
        "    # keys, labels = df[chosen['id']].tolist(), df[chosen['pcr']].tolist()\n",
        "    # data_path = []\n",
        "    # data_uuid = []\n",
        "    # data_label = []\n",
        "    # for key, label in list(zip(keys, labels)):\n",
        "    #     data_uuid.append(key)\n",
        "    #     data_path.append(key + '.wav')\n",
        "    #     data_label.append(label)\n",
        "    #     if label == 'positive' and status == True:\n",
        "    #         # print(label)\n",
        "    #         data_uuid.append(key + '_not_noise')\n",
        "    #         data_uuid.append(key + '_add_noise')\n",
        "    #         data_label.append(label)\n",
        "    #         data_label.append(label)\n",
        "    #         data_path.append(key + '_not_noise.wav')\n",
        "    #         data_path.append(key + '_add_noise.wav')\n",
        "    \n",
        "    metadata_audio = {\n",
        "        'uuid': data_uuid,\n",
        "        'path': data_path,\n",
        "        'labels': data_labels\n",
        "    }\n",
        "    df = pd.DataFrame(metadata_audio, columns=['uuid', 'path', 'labels'])\n",
        "    print(df)\n",
        "    df.to_csv(savedir + name, index=False, header=True)\n",
        "\n",
        "\n",
        "# def process_data_aug(train_df, test_df, dir_train, dir_test, save_train, save_test, csv_train, csv_test):\n",
        "#     train_dataframe, train_chosen = filter_DF(train_df)\n",
        "#     test_dataframe, test_chosen = filter_DF(test_df)\n",
        "\n",
        "#     print(train_dataframe)\n",
        "#     print(train_chosen)\n",
        "    \n",
        "#     keys_train, path_train, labels_train = data_augmentation(train_dataframe, train_chosen, dir_train, True)\n",
        "#     print(keys_train.shape, path_train.shape, labels_train.shape)\n",
        "#     save_csv_data_audio(keys_train, path_train, labels_train, save_train, csv_train)\n",
        "\n",
        "#     print(test_dataframe)\n",
        "#     print(test_chosen)\n",
        "#     keys_test, path_test, labels_test = data_augmentation(test_dataframe, test_chosen, dir_test, False)\n",
        "#     print(keys_test.shape, path_test.shape, labels_test.shape)\n",
        "#     save_csv_data_audio(keys_test, path_test, labels_test, save_test, csv_test)\n",
        "\n",
        "#     return keys_train, labels_train, keys_test, labels_test\n",
        "\n",
        "\n",
        "def process_data_aug_v2(train_df, test_df, dir_train, dir_test, save_train, save_test, csv_train, csv_test):\n",
        "    train_dataframe, train_chosen = filter_DF(train_df)\n",
        "    test_dataframe, test_chosen = filter_DF(test_df)\n",
        "\n",
        "    print(train_dataframe)\n",
        "    print(train_chosen)\n",
        "    \n",
        "    keys_train, data_train, labels_train = data_augmentation(train_dataframe, train_chosen, dir_train, True)\n",
        "    print(keys_train.shape, data_train.shape, labels_train.shape)\n",
        "    # save_csv_data_audio(keys_train, path_train, labels_train, save_train, csv_train)\n",
        "\n",
        "    print(test_dataframe)\n",
        "    print(test_chosen)\n",
        "    keys_test, data_test, labels_test = data_augmentation(test_dataframe, test_chosen, dir_test, False)\n",
        "    print(keys_test.shape, data_test.shape, labels_test.shape)\n",
        "    # save_csv_data_audio(keys_test, path_test, labels_test, save_test, csv_test)\n",
        "\n",
        "    return data_train, labels_train, data_test, labels_test\n",
        "\n",
        "\n",
        "def extract_audio_to_image(file_csv, folder, savedir):\n",
        "    if not os.path.isdir(savedir):\n",
        "        os.mkdir(savedir)\n",
        "\n",
        "    uuid = np.array(pd.read_csv(file_csv, usecols=['uuid'])).T[0]\n",
        "    labels = np.array(pd.read_csv(file_csv, usecols=['labels'])).T[0]\n",
        "    audio_file =  np.array(pd.read_csv(file_csv, usecols=['path'])).T[0]\n",
        "\n",
        "    for id, name in list(zip(uuid, audio_file)):\n",
        "        y, sr = librosa.load(folder + name)\n",
        "        path = get_melspec(savedir, y, sr, id)\n",
        "        print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Coh95g2N9KVH"
      },
      "outputs": [],
      "source": [
        "# aug_train = '/content/drive/MyDrive/virufy_data/audio_train/'\n",
        "# aug_test = '/content/drive/MyDrive/virufy_data/audio_test/'\n",
        "# csv_audio_train = '/content/drive/MyDrive/virufy_data/metadata_audio_train.csv'\n",
        "# csv_audio_test = '/content/drive/MyDrive/virufy_data/metadata_audio_test.csv'\n",
        "\n",
        "version = 'v1MFCCsF13'\n",
        "\n",
        "image_train = '/content/drive/MyDrive/virufy_data/image_train_'+ version\n",
        "image_test = '/content/drive/MyDrive/virufy_data/image_test_'+ version\n",
        "\n",
        "save_csv = '/content/drive/MyDrive/virufy_data/'\n",
        "\n",
        "meta_train = 'metadata_train_aug_'+ version +'.csv'\n",
        "meta_test = 'metadata_test_aug_'+ version +'.csv'\n",
        "\n",
        "train_data, train_labels, test_data, test_labels = process_data_aug_v2(cdf_train, cdf_test, image_train, image_test, save_csv, save_csv, meta_train, meta_test)\n",
        "\n",
        "save_dump('/content/drive/MyDrive/virufy_data/data_feature_aug_'+ version +'.data', train_data, train_labels)\n",
        "save_dump('/content/drive/MyDrive/virufy_data/data_feature_test_aug_'+ version +'.data', test_data, test_labels)\n",
        "view_chart([sum(train_labels == 'positive'), sum(train_labels == 'negative')], ['positive', 'negative'], 'Chart Data Train')\n",
        "view_chart([sum(test_labels == 'positive'), sum(test_labels == 'negative')], ['positive', 'negative'], 'Chart Data Test')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61G0-WDo8URB",
        "outputId": "4136d7d9-6c5a-4e88-b4a6-e5d36a64c547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(302, 128)\n"
          ]
        }
      ],
      "source": [
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "def show_image(_image):\n",
        "    plt.rcParams[\"figure.figsize\"] = (2.24, 2.24)\n",
        "    fig, ax = plt.subplots()\n",
        "    img = librosa.display.specshow(_image, ax=ax)\n",
        "    plt.style.use('classic')\n",
        "    fig.colorbar(img, ax=ax)\n",
        "    ax.set(title='IMG')\n",
        "    plt.show()\n",
        "    pass\n",
        "\n",
        "\n",
        "def save_image(_mfc, _path):\n",
        "    plt.rcParams[\"figure.figsize\"] = (2.24, 2.24)\n",
        "    fig, ax = plt.subplots()\n",
        "    librosa.display.specshow(_mfc, ax=ax)\n",
        "    plt.savefig(_path)\n",
        "    plt.cla()\n",
        "    plt.clf()\n",
        "    plt.close('all')\n",
        "    pass\n",
        "\n",
        "\n",
        "def lib_mfc_mean_matrix(_y, _sr):\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=256, fmax=16000)\n",
        "    mfc = librosa.feature.mfcc(S=librosa.power_to_db(mel, ref=np.max), n_mfcc=2000)\n",
        "    mfc -= np.mean(mfc, axis=0) + 1e-8\n",
        "    return mfc\n",
        "\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "def get_image(image_path):\n",
        "    return cv2.imread(image_path)\n",
        "    # return cv2.resize(cv2.imread(image_path), dsize=(480, 640))\n",
        "    # return preprocess_input(image.img_to_array(image.load_img(image_path, target_size=(480, 640, 3))))\n",
        "\n",
        "def get_melspec(audio,sr):\n",
        "    # Mel Spectogram\n",
        "    melspec  = librosa.feature.melspectrogram(y=audio,sr=sr,n_mels=128, fmax=8000)\n",
        "    s_db     = librosa.power_to_db(melspec, ref=np.max)\n",
        "    rawSBD = s_db.T.tolist()\n",
        "    return rawSBD\n",
        "\n",
        "\n",
        "y, sr = librosa.load('/content/virufy-cdf-coughvid/virufy-cdf-coughvid/0007c6f1-5441-40e6-9aaf-a761d8f2da3b.webm', 22050)\n",
        "y = librosa.util.fix_length(y, size=154350)\n",
        "# print(y.shape)\n",
        "# print(sr)\n",
        "\n",
        "# mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
        "# print(np.array(mel).shape)\n",
        "\n",
        "img = get_melspec(y, 22050)\n",
        "\n",
        "print(np.array(img).shape)\n",
        "\n",
        "# print(img)\n",
        "# print(img.shape)\n",
        "# save_image(img, '/content/drive/MyDrive/dataset/DATA_SET_AUDIO/image_test_2.png')\n",
        "# # # show_image(img)\n",
        "# image_test = get_image('/content/drive/MyDrive/dataset/DATA_SET_AUDIO/test2.png')\n",
        "# print(image_test.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "virufy_cdf_quickstart_v2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}